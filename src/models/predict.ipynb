{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba13bf5-d02e-4cd8-bcce-46bdf00264bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Jan 22 11:35:46 2024\n",
    "\n",
    "@author: Michaela Alksne\n",
    "\n",
    "Script to use the model for running inference, or predicting on new data.\n",
    "Our model has a \"predict\" function which we can call to predict on a new dataset. \n",
    "In this case, we are predicting on our test data. Therefore we are able to generate preformance metrics as described below. \n",
    "However, if we were predicting on unlabeled data, we would just the use the models predict function and would not be able to plot the preformance metrics.\n",
    "\n",
    "Here we load in our trained model and modify the spectrogram parameters because our test data has a different sampling rate than our training data. This will not effect the model. This is just resizing the images so they match. \n",
    "Our model has a \"predict\" function which we can call to predict on a new dataset. \n",
    "    - We load in our model and our test data and generate predictions. \n",
    "    - Then we join the predictions with the true labels and evaluate model preformance by plotting our precision-recall curve using scikit learn\n",
    "    - We also plot the distribution of our scores for true and false detections. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde21371-83de-4869-bc37-a905ceec7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensoundscape\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import librosa\n",
    "import torch\n",
    "import wandb\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d92287-3207-4cf9-93a4-272b398fc151",
   "metadata": {},
   "outputs": [],
   "source": [
    " # read in test dataframes\n",
    "test_clips = pd.read_csv('../../data/processed/test.csv') # point to csv files\n",
    "print(test_clips.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6d80b-01e1-4b60-9334-a75fd8b13e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify relative filepaths \n",
    "data_path = \"YOUR\\DATA\\PATH\\HERE\" # copy and paste the path to your wav files\n",
    "test_clips['file'] = test_clips.file.str.replace(\"..\\\\..\\\\data\\\\raw\\\\\", data_path)\n",
    "test_clips.set_index(['file', 'start_time', 'end_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b99143-a1c2-4f54-88de-16448219e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = opensoundscape.ml.cnn.load_model('../../models/best.model')\n",
    "\n",
    "# moodify model preprocessing for making spectrograms with proper resolution\n",
    "model.preprocessor.pipeline.to_spec.params.window_type = 'hamming' # using hamming window\n",
    "model.preprocessor.pipeline.to_spec.params.window_samples = 1000 # window samples\n",
    "model.preprocessor.pipeline.to_spec.params.overlap_samples = 900 # 90% overlap, for 3200 Fs this means 900 samples, and 0.05 sec bins\n",
    "model.preprocessor.pipeline.to_spec.params.fft_size = 2000 # FFT = Fs, 1 Hz bins\n",
    "model.preprocessor.pipeline.to_spec.params.decibel_limits = (-120,150) # oss preprocessing sets dB limits.\n",
    "\n",
    "# predict \n",
    "test_scores = model.predict(test_clips, num_workers=12,batch_size=128)\n",
    "test_scores.columns = ['pred_A','pred_B']\n",
    "test_all = test_clips.join(test_scores)\n",
    "#save output \n",
    "#test_all.to_csv(repo_path/'labeled_data'/'train_val_test_clips'/'test_clips_prediction.csv')\n",
    "    \n",
    "## B CALLS ###\n",
    "\n",
    "# plot precision recall curve for B calls\n",
    "precision, recall, thresholds = precision_recall_curve(test_all['B NE Pacific'], test_all['pred_B'])\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve B calls test data')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "plt.savefig('../../reports/figures/B_call_PR_curve.svg', format='svg', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()\n",
    "\n",
    "# plot score distribution B calls \n",
    "B_eval_index = test_all.index[test_all['B NE Pacific']==1]\n",
    "B_eval = test_all.loc[B_eval_index]\n",
    "B_noise_index = test_all.index[test_all['B NE Pacific']==0]\n",
    "B_noise = test_all.loc[B_noise_index]\n",
    "plt.hist(B_noise['pred_B'],bins=40,alpha=0.5,edgecolor='black',color='blue',label='Noise prediction score')\n",
    "plt.hist(B_eval['pred_B'],bins=40,alpha=0.5,edgecolor='black',color='orange',label='B call prediction score')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.semilogy()\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('B call prediction scores test data')\n",
    "plt.savefig('../../reports/figures/B_call_prediction_histogram.svg', format='svg', bbox_inches='tight', pad_inches=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
